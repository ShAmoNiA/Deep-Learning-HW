{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2f3a8fd1-25a9-426d-a6be-c93b750cbcb8",
      "metadata": {
        "id": "2f3a8fd1-25a9-426d-a6be-c93b750cbcb8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "47a53036-31ab-4374-bf15-a4dca17a7cbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "47a53036-31ab-4374-bf15-a4dca17a7cbf",
        "outputId": "358d45a3-fc64-4fde-bb2b-fad0dfa313c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>چگونه می توان از موفقیت آمیز بودن خرید اینترنت...</td>\n",
              "      <td>پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>چگونه باید از موفقیت آمیز بودن خرید اینترنتی ه...</td>\n",
              "      <td>پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>از چه راهی باید وضعیت خرید اینترنتی را مشاهده ...</td>\n",
              "      <td>پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>روشی که می‌توان مطمئن شد خرید اینترنتی به درست...</td>\n",
              "      <td>پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>برای این‌که مطمئن بشیم که خرید اینترنتی به درس...</td>\n",
              "      <td>پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  چگونه می توان از موفقیت آمیز بودن خرید اینترنت...   \n",
              "1  چگونه باید از موفقیت آمیز بودن خرید اینترنتی ه...   \n",
              "2  از چه راهی باید وضعیت خرید اینترنتی را مشاهده ...   \n",
              "3  روشی که می‌توان مطمئن شد خرید اینترنتی به درست...   \n",
              "4  برای این‌که مطمئن بشیم که خرید اینترنتی به درس...   \n",
              "\n",
              "                                              answer  \n",
              "0  پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...  \n",
              "1  پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...  \n",
              "2  پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...  \n",
              "3  پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...  \n",
              "4  پس ‎‎‎‎‎‎‎‎‎‎‎‎‎از انجام خرید سیم کارت از طریق...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csvFile = 'HW/Extension1.xlsx'\n",
        "df = pd.read_excel(csvFile, engine='openpyxl',)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4b9bcf18",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = {} \n",
        "counter = 0\n",
        "for count in range(len(df.answer)):\n",
        "    if df.answer[count] == df.answer[count]:\n",
        "        if df.answer[count] not in labels.values(): \n",
        "            labels[counter] = df.answer[count]\n",
        "            counter +=1\n",
        "        df.answer[count] = counter\n",
        "    \n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ab965eff-e1eb-416f-b80c-850554d8026c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "ab965eff-e1eb-416f-b80c-850554d8026c",
        "outputId": "e303ee3a-950a-452b-bed2-1608a47d3a6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='answer'>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.groupby(['answer']).size().plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13f5b1d",
      "metadata": {},
      "source": [
        "##Dataset Class\n",
        "\n",
        "Now that we know what kind of output that we will get from BertTokenizer , let’s build a Dataset class for our news dataset that will serve as a class to generate our news data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5074c270-ed3e-4e1a-863d-71737c743cb8",
      "metadata": {
        "id": "5074c270-ed3e-4e1a-863d-71737c743cb8"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "# labels = {'positive':1,\n",
        "#           'negative':0,\n",
        "#           }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label-1] for label in df['answer']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['question']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77357e00",
      "metadata": {},
      "source": [
        "in the above implementation, we define a variable called labels , which is a dictionary that maps the category in the dataframe into the id representation of our label. Notice that we also call BertTokenizer in the __init__ function above to transform our input texts into the format that BERT expects.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598e1ca0",
      "metadata": {},
      "source": [
        "##Model Building\n",
        "\n",
        "So far, we have built a dataset class to generate our data. Now let’s build the actual model using a pre-trained BERT base model which has 12 layers of Transformer encoder.\n",
        "\n",
        "If your dataset is not in English, it would be best if you use bert-base-multilingual-cased model. If your data is in German, Dutch, Chinese, Japanese, or Finnish, you can use the model pre-trained specifically in these languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0c8a5d0f-80c3-42b3-9f06-ecfc3a21f395",
      "metadata": {
        "id": "0c8a5d0f-80c3-42b3-9f06-ecfc3a21f395"
      },
      "outputs": [],
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7287bef",
      "metadata": {},
      "source": [
        "As you can see from the code above, BERT model outputs two variables:\n",
        "\n",
        "The first variable, which we named _ in the code above, contains the embedding vectors of all of the tokens in a sequence.\n",
        "\n",
        "The second variable, which we named pooled_output, contains the embedding vector of [CLS] token. For a text classification task, it is enough to use this embedding as an input for our classifier.\n",
        "\n",
        "We then pass the pooled_output variable into a linear layer with ReLU activation function. At the end of the linear layer, we have a vector of size 5, each corresponds to a category of our labels (sport, business, politics, entertainment, and tech)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb787ba",
      "metadata": {},
      "source": [
        "##Training Loop\n",
        "\n",
        "Now it’s time for us to train the model. The training loop will be a standard PyTorch training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fa1f1cf7-65db-4966-9a55-ba26bd22ed6c",
      "metadata": {
        "id": "fa1f1cf7-65db-4966-9a55-ba26bd22ed6c"
      },
      "outputs": [],
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "                  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2319d7e8",
      "metadata": {},
      "source": [
        "##Evaluate Model on Test Data\n",
        "\n",
        "Now that we have trained the model, we can use the test data to evaluate the model’s performance on unseen data. Below is the function to evaluate the performance of the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cd8a670d-c449-45fe-8f4c-9a5fb27855c1",
      "metadata": {
        "id": "cd8a670d-c449-45fe-8f4c-9a5fb27855c1"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae35f76f",
      "metadata": {},
      "source": [
        "\n",
        "After defining dataset class, let’s split our dataframe into training, validation, and test set with the proportion of 80:10:10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "25d2231d-fef1-42cf-a73e-188cac932727",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25d2231d-fef1-42cf-a73e-188cac932727",
        "outputId": "0abe57a9-4a8c-4072-9eda-dc71d8af3e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1036 130 130\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c9fea87",
      "metadata": {},
      "source": [
        "We train the model for 5 epochs and we use Adam as the optimizer, while the learning rate is set to 1e-6. We also need to use categorical cross entropy as our loss function since we’re dealing with multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "30242239-de70-4c03-8f56-9f5ade43518d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30242239-de70-4c03-8f56-9f5ade43518d",
        "outputId": "f79931ff-bf09-41a8-e2da-a0adeeb647fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e23a81fa3b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-4671a567da4f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace16/Shayan/Shayan-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace16/Shayan/Shayan-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace16/Shayan/Shayan-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace16/Shayan/Shayan-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace16/Shayan/Shayan-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/workspace16/Shayan/Shayan-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "from_tf=True\n",
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "              \n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc00f0a-9a15-4942-9c9b-2f9789c8dd22",
      "metadata": {
        "id": "ccc00f0a-9a15-4942-9c9b-2f9789c8dd22"
      },
      "outputs": [],
      "source": [
        "evaluate(model, df_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bert_medium.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "vscode": {
      "interpreter": {
        "hash": "5e8a27ab8acb2096dc713806039eabb4d439e83f2c9052f097a76710800907fc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
