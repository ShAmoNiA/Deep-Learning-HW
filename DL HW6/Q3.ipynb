{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zmxo2g4QGjOh"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import  Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from scipy.ndimage import rotate\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSXHDbbZLHZ0"
   },
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9-gUZ9ZwLHEH"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "unlabeld_index = np.ones(y_train.shape, np.bool)\n",
    "\n",
    "N = 20\n",
    "for i in range(10):\n",
    "  idx = np.where(y_train == i)[0][:N]\n",
    "  unlabeld_index[idx] = 0\n",
    "\n",
    "x_unlabeld = x_train[np.where(unlabeld_index)[0], ...]\n",
    "\n",
    "x_train = x_train[np.where(~unlabeld_index)[0], ...]\n",
    "y_train = y_train[np.where(~unlabeld_index)[0], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AdM1DXorH9eJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051293306\n",
      "-0.0\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "# examples of categorical crossentropy\n",
    "cce = keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# a labeled data from the second class\n",
    "y_true = [[0, 1, 0, 0]]\n",
    "y_pred = [[0.05, 0.95, 0, 0]]\n",
    "print(cce(y_true, y_pred).numpy())\n",
    "\n",
    "# an ulabeled data\n",
    "y_true = [[0, 0, 0, 0]]\n",
    "y_pred = [[0.05, 0.95, 0, 0]]\n",
    "print(cce(y_true, y_pred).numpy())\n",
    "\n",
    "# another ulabeled data\n",
    "y_true = [[0, 0, 0, 0]]\n",
    "y_pred = [[0.1, 0.4, 0.3, 0.2]]\n",
    "print(cce(y_true, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train/255\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test/255\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = tf.keras.models.Sequential()\n",
    "\n",
    "X.add(tf.keras.applications.ResNet50(include_top=False, input_shape=(32, 32, 3), weights=None))\n",
    "X.add(Flatten(name=\"flatten\"))\n",
    "X.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "X.summary()\n",
    "\n",
    "X.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "               loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7/7 [==============================] - 7s 549ms/step - loss: 5.5109 - accuracy: 0.0800\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 4s 546ms/step - loss: 4.5375 - accuracy: 0.1550\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 4s 544ms/step - loss: 3.0213 - accuracy: 0.2350\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 2.1538 - accuracy: 0.3000\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 4s 543ms/step - loss: 2.2300 - accuracy: 0.4250\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 1.7327 - accuracy: 0.5150\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 1.1938 - accuracy: 0.7100\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 4s 551ms/step - loss: 0.8431 - accuracy: 0.7850\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.6555 - accuracy: 0.8300\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.5738 - accuracy: 0.9150\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 4s 544ms/step - loss: 0.3082 - accuracy: 0.9200\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 4s 544ms/step - loss: 0.5242 - accuracy: 0.8950\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.6814 - accuracy: 0.8650\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 4s 544ms/step - loss: 0.5687 - accuracy: 0.8850\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.5983 - accuracy: 0.8900\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 4s 551ms/step - loss: 0.6396 - accuracy: 0.9050\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.3591 - accuracy: 0.9100\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.5608 - accuracy: 0.9000\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 0.6099 - accuracy: 0.8850\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.5729 - accuracy: 0.8550\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 4s 552ms/step - loss: 0.6435 - accuracy: 0.8500\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 4s 554ms/step - loss: 0.6425 - accuracy: 0.8900\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.4886 - accuracy: 0.8800\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 0.6221 - accuracy: 0.8800\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 4s 556ms/step - loss: 0.6576 - accuracy: 0.7900\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 0.6838 - accuracy: 0.8800\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 4s 555ms/step - loss: 0.6165 - accuracy: 0.8700\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 0.3880 - accuracy: 0.9400\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 4s 556ms/step - loss: 0.2055 - accuracy: 0.9400\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 4s 553ms/step - loss: 0.4732 - accuracy: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac13b16b00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.fit(x_train, y_train, batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 19ms/step - loss: 3.4984 - accuracy: 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.498427391052246, 0.09989999979734421]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new= []\n",
    "y_train_new = []\n",
    "\n",
    "x_unlabeld = x_unlabeld.astype('float32')\n",
    "x_unlabeld = x_unlabeld/255\n",
    "\n",
    "degrees = [0,90,180,270]\n",
    "\n",
    "for images in x_unlabeld:\n",
    "  for degree in degrees:\n",
    "    x_train_new.append(rotate(images, angle=degree))\n",
    "    y = np.zeros(4)\n",
    "    y[degrees.index(degree)] = 1\n",
    "    y_train_new.append(y)\n",
    "\n",
    "x_rotated = np.array(x_train_new)\n",
    "y_rotated = np.array(y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_32 (Functiona (None, 1, 1, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 3,232,964\n",
      "Trainable params: 3,211,076\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_rotate = tf.keras.models.Sequential()\n",
    "\n",
    "X_rotate.add(tf.keras.applications.MobileNet(include_top=False, input_shape=(32, 32, 3), weights=None))\n",
    "X_rotate.add(Flatten(name=\"flatten\"))\n",
    "X_rotate.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "X_rotate.summary()\n",
    "\n",
    "X_rotate.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1557/1557 [==============================] - 401s 257ms/step - loss: 0.7739 - accuracy: 0.6869\n",
      "Epoch 2/10\n",
      "1557/1557 [==============================] - 402s 258ms/step - loss: 0.7206 - accuracy: 0.7129\n",
      "Epoch 3/10\n",
      "1557/1557 [==============================] - 402s 258ms/step - loss: 0.6637 - accuracy: 0.7366\n",
      "Epoch 4/10\n",
      "1557/1557 [==============================] - 401s 257ms/step - loss: 0.6162 - accuracy: 0.7578\n",
      "Epoch 5/10\n",
      "1557/1557 [==============================] - 401s 258ms/step - loss: 0.5680 - accuracy: 0.7787\n",
      "Epoch 6/10\n",
      "1557/1557 [==============================] - 402s 258ms/step - loss: 0.5283 - accuracy: 0.7947\n",
      "Epoch 7/10\n",
      "1557/1557 [==============================] - 402s 258ms/step - loss: 0.4937 - accuracy: 0.8096\n",
      "Epoch 8/10\n",
      "1557/1557 [==============================] - 402s 258ms/step - loss: 0.4599 - accuracy: 0.8218\n",
      "Epoch 9/10\n",
      "1557/1557 [==============================] - 402s 258ms/step - loss: 0.4248 - accuracy: 0.8373\n",
      "Epoch 10/10\n",
      "1557/1557 [==============================] - 402s 258ms/step - loss: 0.3922 - accuracy: 0.8495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fabf415ba58>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rotate.fit(x_rotated, y_rotated, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = keras.Model(X.inputs, Dense(10 ,activation='softmax')(X.layers[-2].output))\n",
    "X_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7/7 [==============================] - 7s 545ms/step - loss: 3.0474 - accuracy: 0.2750\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 2.3747 - accuracy: 0.3400\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 1.3775 - accuracy: 0.6150\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 4s 546ms/step - loss: 1.4457 - accuracy: 0.6750\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 1.0635 - accuracy: 0.6750\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.7695 - accuracy: 0.8100\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 1.1478 - accuracy: 0.6900\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 1.1912 - accuracy: 0.6750\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 1.0723 - accuracy: 0.6900\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.7754 - accuracy: 0.8250\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 0.4622 - accuracy: 0.8800\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 1.1217 - accuracy: 0.7750\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 1.0983 - accuracy: 0.7100\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 4s 546ms/step - loss: 0.8278 - accuracy: 0.7550\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 0.4999 - accuracy: 0.8900\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 0.4943 - accuracy: 0.8900\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 4s 546ms/step - loss: 0.4900 - accuracy: 0.9300\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 4s 553ms/step - loss: 0.7997 - accuracy: 0.8850\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 1.2754 - accuracy: 0.7650\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 1.5234 - accuracy: 0.6300\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 0.9871 - accuracy: 0.7650\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 4s 546ms/step - loss: 1.0694 - accuracy: 0.8350\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 4s 546ms/step - loss: 0.6566 - accuracy: 0.9100\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 4s 549ms/step - loss: 1.4038 - accuracy: 0.7100\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 1.3681 - accuracy: 0.6850\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 4s 547ms/step - loss: 1.1738 - accuracy: 0.7000\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 4s 550ms/step - loss: 1.0134 - accuracy: 0.7850\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 1.0418 - accuracy: 0.7800\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 4s 548ms/step - loss: 0.8421 - accuracy: 0.8350\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.6671 - accuracy: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64a6a95cf8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.fit(x_train, y_train, batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new= []\n",
    "y_train_new = []\n",
    "y_classification = []\n",
    "\n",
    "\n",
    "x_unlabeld = x_unlabeld.astype('float32')\n",
    "x_unlabeld = x_unlabeld/255\n",
    "\n",
    "degrees = [0,90,180,270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in x_unlabeld:\n",
    "    for degree in degrees:\n",
    "        x_train_new.append(rotate(images, angle=degree))\n",
    "        y = np.zeros(4)\n",
    "        y[degrees.index(degree)] = 1\n",
    "        y_train_new.append(y)\n",
    "        y_classification.append(np.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in x_train:\n",
    "    for degree in degrees:\n",
    "      x_train_new.append(rotate(images, angle=degree))\n",
    "      y = np.zeros(4)\n",
    "      y[degrees.index(degree)] = 1\n",
    "      y_train_new.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Y in range(len(x_train)):\n",
    "    for x in range(4):\n",
    "        y_classification.append(y_train[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rotated = np.array(x_train_new)\n",
    "y_rotated = np.array(y_train_new)\n",
    "y_classification = np.array(y_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 32, 32, 3)\n",
      "(200000, 10)\n",
      "(200000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_rotated.shape)\n",
    "print(y_classification.shape)\n",
    "print(y_rotated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout, Input, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(classification,rotation):\n",
    "    INp = Input(shape=(x_train.shape[1:]),)\n",
    "    Conv2D_ = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(INp)\n",
    "    pool = MaxPooling2D(pool_size=(3, 3))(Conv2D_)\n",
    "    Do = Dropout(rate=0.2)(pool)\n",
    "    Conv2D_ = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(Do)\n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(Conv2D_)\n",
    "    Do = Dropout(rate=0.2)(pool)\n",
    "    Conv2D_ = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(Do)\n",
    "    flt = Flatten()(Conv2D_)\n",
    "    dense = Dense(units=1024, activation='relu')(flt)\n",
    "    Hold = keras.Model(inputs=INp, outputs=dense)\n",
    "\n",
    "    \n",
    "    classifier = Dense(units=10, activation='softmax', name='classifier')(Hold.outputs[0])\n",
    "    rotator = Dense(units=4, activation='softmax', name='rotator')(Hold.outputs[0])\n",
    "\n",
    "    model_double = keras.Model(inputs=Hold.inputs, outputs=[classifier, rotator])\n",
    "    \n",
    "    model_double.compile(optimizer='adam', metrics=['accuracy'], loss_weights={'classifier': 10,'rotator': 1}, loss='categorical_crossentropy')\n",
    "\n",
    "    history = model_double.fit(\n",
    "        x_rotated,\n",
    "        [y_classification,y_rotated],\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        validation_split = 0.2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classification,rotation):\n",
    "    MobileNet_model = tf.keras.applications.MobileNet(include_top=False, input_shape=(32, 32, 3), weights=None)\n",
    "    flat = Flatten()(MobileNet_model.layers[-1].output)\n",
    "    denseA = Dense(128, activation='relu')(flat)\n",
    "    dense4 = Dense(4, activation='softmax', name='rotation')(denseA)\n",
    "    dense10 = Dense(10, activation='softmax', name='classification')(denseA)\n",
    "    \n",
    "    model_double = Model(inputs=MobileNet_model.inputs, outputs=[dense10, dense4])\n",
    "\n",
    "    model_double.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001) ,loss_weights={'classification': classification,'rotation': rotation},\n",
    "                        loss={'classification': 'categorical_crossentropy', 'rotation': 'categorical_crossentropy'},\n",
    "                        metrics={'classification': 'accuracy','rotation': 'accuracy'})\n",
    "\n",
    "    history = model_double.fit(\n",
    "        x_rotated,\n",
    "        [y_classification,y_rotated],\n",
    "        batch_size=128,\n",
    "        epochs=10,\n",
    "        validation_split = 0.2)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = len(x_rotated) - 1\n",
    "plt.imshow(x_rotated[A-1])\n",
    "print(y_classification[A-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 321s 255ms/step - loss: 53.4203 - classification_loss: 0.0000e+00 - rotation_loss: 53.4203 - classification_accuracy: 0.0897 - rotation_accuracy: 0.2480 - val_loss: 160.9313 - val_classification_loss: 7.1942 - val_rotation_loss: 124.9602 - val_classification_accuracy: 0.0022 - val_rotation_accuracy: 0.2529\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 338.5016 - classification_loss: 0.0000e+00 - rotation_loss: 338.5016 - classification_accuracy: 0.1022 - rotation_accuracy: 0.2495 - val_loss: 489.5877 - val_classification_loss: 15.8368 - val_rotation_loss: 410.4037 - val_classification_accuracy: 0.0019 - val_rotation_accuracy: 0.2542\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 323s 258ms/step - loss: 549.2380 - classification_loss: 0.0000e+00 - rotation_loss: 549.2380 - classification_accuracy: 0.1010 - rotation_accuracy: 0.2502 - val_loss: 694.3292 - val_classification_loss: 24.7359 - val_rotation_loss: 570.6497 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 323s 258ms/step - loss: 691.4822 - classification_loss: 0.0000e+00 - rotation_loss: 691.4822 - classification_accuracy: 0.1012 - rotation_accuracy: 0.2523 - val_loss: 378.7582 - val_classification_loss: 41.0921 - val_rotation_loss: 173.2975 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2514\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 323s 258ms/step - loss: 803.3528 - classification_loss: 0.0000e+00 - rotation_loss: 803.3528 - classification_accuracy: 0.1012 - rotation_accuracy: 0.2502 - val_loss: 556.5586 - val_classification_loss: 13.4317 - val_rotation_loss: 489.4001 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 323s 258ms/step - loss: 978.5768 - classification_loss: 0.0000e+00 - rotation_loss: 978.5768 - classification_accuracy: 0.1000 - rotation_accuracy: 0.2521 - val_loss: 1880.4960 - val_classification_loss: 47.7746 - val_rotation_loss: 1641.6230 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 323s 259ms/step - loss: 1152.8545 - classification_loss: 0.0000e+00 - rotation_loss: 1152.8545 - classification_accuracy: 0.0992 - rotation_accuracy: 0.2492 - val_loss: 2182.8831 - val_classification_loss: 38.1580 - val_rotation_loss: 1992.0930 - val_classification_accuracy: 0.0019 - val_rotation_accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 323s 258ms/step - loss: 1403.2993 - classification_loss: 0.0000e+00 - rotation_loss: 1403.2993 - classification_accuracy: 0.0992 - rotation_accuracy: 0.2505 - val_loss: 1461.4019 - val_classification_loss: 79.4970 - val_rotation_loss: 1063.9171 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 322s 258ms/step - loss: 1540.4510 - classification_loss: 0.0000e+00 - rotation_loss: 1540.4510 - classification_accuracy: 0.0992 - rotation_accuracy: 0.2538 - val_loss: 1788.2845 - val_classification_loss: 85.8714 - val_rotation_loss: 1358.9275 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2562\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 322s 258ms/step - loss: 1782.6240 - classification_loss: 0.0000e+00 - rotation_loss: 1782.6240 - classification_accuracy: 0.0990 - rotation_accuracy: 0.2523 - val_loss: 2907.8628 - val_classification_loss: 92.1923 - val_rotation_loss: 2446.9014 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34f40444a8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 326s 260ms/step - loss: 69.5134 - classification_loss: 0.0000e+00 - rotation_loss: 69.5134 - classification_accuracy: 0.1124 - rotation_accuracy: 0.2544 - val_loss: 21.6016 - val_classification_loss: 0.4993 - val_rotation_loss: 21.1022 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 382.2999 - classification_loss: 0.0000e+00 - rotation_loss: 382.2999 - classification_accuracy: 0.0849 - rotation_accuracy: 0.2502 - val_loss: 235.6201 - val_classification_loss: 14.1501 - val_rotation_loss: 221.4700 - val_classification_accuracy: 0.0018 - val_rotation_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 622.4053 - classification_loss: 0.0000e+00 - rotation_loss: 622.4053 - classification_accuracy: 0.0957 - rotation_accuracy: 0.2523 - val_loss: 898.0247 - val_classification_loss: 29.0135 - val_rotation_loss: 869.0112 - val_classification_accuracy: 0.0021 - val_rotation_accuracy: 0.2489\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 323s 259ms/step - loss: 747.8642 - classification_loss: 0.0000e+00 - rotation_loss: 747.8642 - classification_accuracy: 0.0983 - rotation_accuracy: 0.2508 - val_loss: 449.2197 - val_classification_loss: 35.5583 - val_rotation_loss: 413.6614 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2525\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 323s 258ms/step - loss: 928.2496 - classification_loss: 0.0000e+00 - rotation_loss: 928.2496 - classification_accuracy: 0.0994 - rotation_accuracy: 0.2502 - val_loss: 467.5351 - val_classification_loss: 50.7407 - val_rotation_loss: 416.7944 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 323s 259ms/step - loss: 1146.0126 - classification_loss: 0.0000e+00 - rotation_loss: 1146.0126 - classification_accuracy: 0.0987 - rotation_accuracy: 0.2491 - val_loss: 1307.1926 - val_classification_loss: 39.2041 - val_rotation_loss: 1267.9886 - val_classification_accuracy: 0.9788 - val_rotation_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 323s 258ms/step - loss: 1292.8956 - classification_loss: 0.0000e+00 - rotation_loss: 1292.8956 - classification_accuracy: 0.0994 - rotation_accuracy: 0.2506 - val_loss: 1308.8528 - val_classification_loss: 41.2110 - val_rotation_loss: 1267.6418 - val_classification_accuracy: 0.0021 - val_rotation_accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 323s 259ms/step - loss: 1428.0503 - classification_loss: 0.0000e+00 - rotation_loss: 1428.0503 - classification_accuracy: 0.1002 - rotation_accuracy: 0.2510 - val_loss: 1569.6022 - val_classification_loss: 67.1457 - val_rotation_loss: 1502.4565 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 323s 259ms/step - loss: 1623.3239 - classification_loss: 0.0000e+00 - rotation_loss: 1623.3239 - classification_accuracy: 0.0999 - rotation_accuracy: 0.2510 - val_loss: 2796.5427 - val_classification_loss: 46.1766 - val_rotation_loss: 2750.3662 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 323s 258ms/step - loss: 1765.8824 - classification_loss: 0.0000e+00 - rotation_loss: 1765.8824 - classification_accuracy: 0.1000 - rotation_accuracy: 0.2508 - val_loss: 2018.0936 - val_classification_loss: 60.6791 - val_rotation_loss: 1957.4144 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34de683da0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 326s 260ms/step - loss: 273.4536 - classification_loss: 0.0000e+00 - rotation_loss: 54.6907 - classification_accuracy: 0.1046 - rotation_accuracy: 0.2513 - val_loss: 369.4855 - val_classification_loss: 5.8851 - val_rotation_loss: 72.7201 - val_classification_accuracy: 0.0018 - val_rotation_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 1519.4174 - classification_loss: 0.0000e+00 - rotation_loss: 303.8833 - classification_accuracy: 0.0848 - rotation_accuracy: 0.2511 - val_loss: 1480.3754 - val_classification_loss: 17.2988 - val_rotation_loss: 292.6153 - val_classification_accuracy: 0.0019 - val_rotation_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 3013.0286 - classification_loss: 0.0000e+00 - rotation_loss: 602.6059 - classification_accuracy: 0.0956 - rotation_accuracy: 0.2486 - val_loss: 4611.8091 - val_classification_loss: 12.1382 - val_rotation_loss: 919.9346 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 3108.3762 - classification_loss: 0.0000e+00 - rotation_loss: 621.6755 - classification_accuracy: 0.0979 - rotation_accuracy: 0.2492 - val_loss: 2249.4209 - val_classification_loss: 20.3572 - val_rotation_loss: 445.8127 - val_classification_accuracy: 0.0021 - val_rotation_accuracy: 0.2500\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 4418.5068 - classification_loss: 0.0000e+00 - rotation_loss: 883.7003 - classification_accuracy: 0.0998 - rotation_accuracy: 0.2509 - val_loss: 3587.8860 - val_classification_loss: 44.1180 - val_rotation_loss: 708.7539 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 5135.5400 - classification_loss: 0.0000e+00 - rotation_loss: 1027.1078 - classification_accuracy: 0.0989 - rotation_accuracy: 0.2518 - val_loss: 6673.8755 - val_classification_loss: 44.1828 - val_rotation_loss: 1325.9386 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 5919.8271 - classification_loss: 0.0000e+00 - rotation_loss: 1183.9650 - classification_accuracy: 0.0990 - rotation_accuracy: 0.2506 - val_loss: 4331.0254 - val_classification_loss: 63.8366 - val_rotation_loss: 853.4368 - val_classification_accuracy: 0.0021 - val_rotation_accuracy: 0.2528\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 324s 260ms/step - loss: 6593.6973 - classification_loss: 0.0000e+00 - rotation_loss: 1318.7399 - classification_accuracy: 0.1008 - rotation_accuracy: 0.2509 - val_loss: 2426.1487 - val_classification_loss: 72.4227 - val_rotation_loss: 470.7462 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2505\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 324s 260ms/step - loss: 7240.7866 - classification_loss: 0.0000e+00 - rotation_loss: 1448.1578 - classification_accuracy: 0.0991 - rotation_accuracy: 0.2505 - val_loss: 3405.8257 - val_classification_loss: 65.3654 - val_rotation_loss: 668.0915 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2517\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 324s 259ms/step - loss: 8978.8271 - classification_loss: 0.0000e+00 - rotation_loss: 1795.7686 - classification_accuracy: 0.1000 - rotation_accuracy: 0.2499 - val_loss: 9199.7861 - val_classification_loss: 63.6782 - val_rotation_loss: 1827.2200 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34de57a898>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 328s 261ms/step - loss: 559.5211 - classification_loss: 0.0000e+00 - rotation_loss: 11.1904 - classification_accuracy: 0.1256 - rotation_accuracy: 0.2642 - val_loss: 1985.2168 - val_classification_loss: 2.0378 - val_rotation_loss: 39.6636 - val_classification_accuracy: 0.1756 - val_rotation_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 325s 260ms/step - loss: 3126.1462 - classification_loss: 0.0000e+00 - rotation_loss: 62.5229 - classification_accuracy: 0.2637 - rotation_accuracy: 0.2502 - val_loss: 214.1960 - val_classification_loss: 0.1171 - val_rotation_loss: 4.2816 - val_classification_accuracy: 0.9820 - val_rotation_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 325s 260ms/step - loss: 6121.7427 - classification_loss: 0.0000e+00 - rotation_loss: 122.4346 - classification_accuracy: 0.1618 - rotation_accuracy: 0.2498 - val_loss: 247.7967 - val_classification_loss: 0.3221 - val_rotation_loss: 4.9495 - val_classification_accuracy: 0.8822 - val_rotation_accuracy: 0.2432\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 326s 261ms/step - loss: 7964.0537 - classification_loss: 0.0000e+00 - rotation_loss: 159.2811 - classification_accuracy: 0.1192 - rotation_accuracy: 0.2543 - val_loss: 6119.7100 - val_classification_loss: 8.6963 - val_rotation_loss: 122.2203 - val_classification_accuracy: 0.0222 - val_rotation_accuracy: 0.2506\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 326s 261ms/step - loss: 10321.4141 - classification_loss: 0.0000e+00 - rotation_loss: 206.4281 - classification_accuracy: 0.1082 - rotation_accuracy: 0.2508 - val_loss: 10048.1943 - val_classification_loss: 8.8167 - val_rotation_loss: 200.7876 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2517\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 326s 261ms/step - loss: 11601.2598 - classification_loss: 0.0000e+00 - rotation_loss: 232.0249 - classification_accuracy: 0.1034 - rotation_accuracy: 0.2519 - val_loss: 7124.8818 - val_classification_loss: 10.5682 - val_rotation_loss: 142.2864 - val_classification_accuracy: 0.0043 - val_rotation_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 326s 261ms/step - loss: 13585.8115 - classification_loss: 0.0000e+00 - rotation_loss: 271.7162 - classification_accuracy: 0.1054 - rotation_accuracy: 0.2497 - val_loss: 32755.6035 - val_classification_loss: 14.0349 - val_rotation_loss: 654.8309 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2508\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 326s 261ms/step - loss: 18686.4727 - classification_loss: 0.0000e+00 - rotation_loss: 373.7296 - classification_accuracy: 0.1073 - rotation_accuracy: 0.2546 - val_loss: 12679.2637 - val_classification_loss: 10.7466 - val_rotation_loss: 253.3704 - val_classification_accuracy: 0.0119 - val_rotation_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 327s 261ms/step - loss: 20854.4199 - classification_loss: 0.0000e+00 - rotation_loss: 417.0883 - classification_accuracy: 0.1046 - rotation_accuracy: 0.2508 - val_loss: 9940.9492 - val_classification_loss: 15.4658 - val_rotation_loss: 198.5094 - val_classification_accuracy: 0.0117 - val_rotation_accuracy: 0.2507\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 326s 261ms/step - loss: 25809.4297 - classification_loss: 0.0000e+00 - rotation_loss: 516.1881 - classification_accuracy: 0.1027 - rotation_accuracy: 0.2515 - val_loss: 27703.1738 - val_classification_loss: 9.4450 - val_rotation_loss: 553.8749 - val_classification_accuracy: 0.0096 - val_rotation_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34de3e7d30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 329s 262ms/step - loss: 75.4261 - classification_loss: 0.0000e+00 - rotation_loss: 75.4261 - classification_accuracy: 0.0823 - rotation_accuracy: 0.2498 - val_loss: 572.3885 - val_classification_loss: 4.9099 - val_rotation_loss: 326.8930 - val_classification_accuracy: 0.0021 - val_rotation_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 369.8727 - classification_loss: 0.0000e+00 - rotation_loss: 369.8727 - classification_accuracy: 0.0987 - rotation_accuracy: 0.2506 - val_loss: 1607.2616 - val_classification_loss: 27.2379 - val_rotation_loss: 245.3686 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 702.9659 - classification_loss: 0.0000e+00 - rotation_loss: 702.9659 - classification_accuracy: 0.1007 - rotation_accuracy: 0.2514 - val_loss: 2515.6101 - val_classification_loss: 24.8766 - val_rotation_loss: 1271.7803 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 890.6745 - classification_loss: 0.0000e+00 - rotation_loss: 890.6745 - classification_accuracy: 0.0991 - rotation_accuracy: 0.2515 - val_loss: 3053.0220 - val_classification_loss: 40.4235 - val_rotation_loss: 1031.8472 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2511\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 326s 261ms/step - loss: 1117.7010 - classification_loss: 0.0000e+00 - rotation_loss: 1117.7010 - classification_accuracy: 0.1061 - rotation_accuracy: 0.2509 - val_loss: 2774.8840 - val_classification_loss: 36.5105 - val_rotation_loss: 949.3605 - val_classification_accuracy: 0.0074 - val_rotation_accuracy: 0.2505\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 326s 261ms/step - loss: 1371.8561 - classification_loss: 0.0000e+00 - rotation_loss: 1371.8561 - classification_accuracy: 0.1009 - rotation_accuracy: 0.2495 - val_loss: 3474.5208 - val_classification_loss: 52.5444 - val_rotation_loss: 847.2983 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 327s 261ms/step - loss: 1465.1028 - classification_loss: 0.0000e+00 - rotation_loss: 1465.1028 - classification_accuracy: 0.0997 - rotation_accuracy: 0.2508 - val_loss: 4061.6016 - val_classification_loss: 60.6426 - val_rotation_loss: 1029.4729 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 1665.9025 - classification_loss: 0.0000e+00 - rotation_loss: 1665.9025 - classification_accuracy: 0.1000 - rotation_accuracy: 0.2493 - val_loss: 4942.6763 - val_classification_loss: 74.7951 - val_rotation_loss: 1202.9226 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 1791.9320 - classification_loss: 0.0000e+00 - rotation_loss: 1791.9320 - classification_accuracy: 0.0994 - rotation_accuracy: 0.2505 - val_loss: 6163.3794 - val_classification_loss: 75.5542 - val_rotation_loss: 2385.6697 - val_classification_accuracy: 0.9820 - val_rotation_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 2014.0286 - classification_loss: 0.0000e+00 - rotation_loss: 2014.0286 - classification_accuracy: 0.1008 - rotation_accuracy: 0.2494 - val_loss: 5028.2681 - val_classification_loss: 68.7202 - val_rotation_loss: 1592.2577 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34d91babe0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 330s 263ms/step - loss: 78.4313 - classification_loss: 0.0000e+00 - rotation_loss: 78.4313 - classification_accuracy: 0.0632 - rotation_accuracy: 0.2489 - val_loss: 2523.4539 - val_classification_loss: 11.4200 - val_rotation_loss: 239.4454 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2371\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 328s 262ms/step - loss: 454.7282 - classification_loss: 0.0000e+00 - rotation_loss: 454.7282 - classification_accuracy: 0.0846 - rotation_accuracy: 0.2509 - val_loss: 2545.3003 - val_classification_loss: 11.5995 - val_rotation_loss: 225.4080 - val_classification_accuracy: 0.0019 - val_rotation_accuracy: 0.2504\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 655.6214 - classification_loss: 0.0000e+00 - rotation_loss: 655.6214 - classification_accuracy: 0.0925 - rotation_accuracy: 0.2504 - val_loss: 6617.5610 - val_classification_loss: 31.3915 - val_rotation_loss: 339.2554 - val_classification_accuracy: 0.0124 - val_rotation_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 805.3012 - classification_loss: 0.0000e+00 - rotation_loss: 805.3012 - classification_accuracy: 0.0979 - rotation_accuracy: 0.2510 - val_loss: 7520.6738 - val_classification_loss: 33.2922 - val_rotation_loss: 862.2408 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 327s 261ms/step - loss: 1029.0167 - classification_loss: 0.0000e+00 - rotation_loss: 1029.0167 - classification_accuracy: 0.0977 - rotation_accuracy: 0.2547 - val_loss: 9225.5684 - val_classification_loss: 34.2414 - val_rotation_loss: 2377.2805 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 1210.9698 - classification_loss: 0.0000e+00 - rotation_loss: 1210.9698 - classification_accuracy: 0.0995 - rotation_accuracy: 0.2537 - val_loss: 12907.1143 - val_classification_loss: 54.8123 - val_rotation_loss: 1944.6598 - val_classification_accuracy: 0.9754 - val_rotation_accuracy: 0.2519\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 328s 262ms/step - loss: 1472.4590 - classification_loss: 0.0000e+00 - rotation_loss: 1472.4590 - classification_accuracy: 0.1010 - rotation_accuracy: 0.2516 - val_loss: 8796.1201 - val_classification_loss: 36.7026 - val_rotation_loss: 1455.6007 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 328s 262ms/step - loss: 1647.1927 - classification_loss: 0.0000e+00 - rotation_loss: 1647.1927 - classification_accuracy: 0.1008 - rotation_accuracy: 0.2507 - val_loss: 7257.8687 - val_classification_loss: 33.1183 - val_rotation_loss: 634.2186 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 1608.6082 - classification_loss: 0.0000e+00 - rotation_loss: 1608.6082 - classification_accuracy: 0.1008 - rotation_accuracy: 0.2503 - val_loss: 12338.5234 - val_classification_loss: 47.6220 - val_rotation_loss: 2814.1248 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 327s 262ms/step - loss: 1911.6112 - classification_loss: 0.0000e+00 - rotation_loss: 1911.6112 - classification_accuracy: 0.1000 - rotation_accuracy: 0.2494 - val_loss: 20150.9922 - val_classification_loss: 91.2862 - val_rotation_loss: 1893.7516 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34da4ab0f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(200,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 331s 264ms/step - loss: 789.4280 - classification_loss: 0.0000e+00 - rotation_loss: 3.9471 - classification_accuracy: 0.1630 - rotation_accuracy: 0.3063 - val_loss: 1605.7920 - val_classification_loss: 0.4453 - val_rotation_loss: 8.0267 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 329s 263ms/step - loss: 6586.7280 - classification_loss: 0.0000e+00 - rotation_loss: 32.9336 - classification_accuracy: 0.1101 - rotation_accuracy: 0.2506 - val_loss: 8718.8096 - val_classification_loss: 2.0347 - val_rotation_loss: 43.5838 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2653\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 329s 263ms/step - loss: 12279.4971 - classification_loss: 0.0000e+00 - rotation_loss: 61.3975 - classification_accuracy: 0.1015 - rotation_accuracy: 0.2500 - val_loss: 32186.0312 - val_classification_loss: 3.0817 - val_rotation_loss: 160.9147 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 329s 263ms/step - loss: 16470.6973 - classification_loss: 0.0000e+00 - rotation_loss: 82.3535 - classification_accuracy: 0.0979 - rotation_accuracy: 0.2524 - val_loss: 6322.5967 - val_classification_loss: 4.2102 - val_rotation_loss: 31.5920 - val_classification_accuracy: 0.0019 - val_rotation_accuracy: 0.2501\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 329s 263ms/step - loss: 22544.2598 - classification_loss: 0.0000e+00 - rotation_loss: 112.7212 - classification_accuracy: 0.0991 - rotation_accuracy: 0.2518 - val_loss: 1179.9640 - val_classification_loss: 0.4193 - val_rotation_loss: 5.8977 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2413\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 328s 263ms/step - loss: 26704.6074 - classification_loss: 0.0000e+00 - rotation_loss: 133.5231 - classification_accuracy: 0.0992 - rotation_accuracy: 0.2509 - val_loss: 34959.7031 - val_classification_loss: 2.7100 - val_rotation_loss: 174.7856 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2503\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 328s 262ms/step - loss: 29233.7383 - classification_loss: 0.0000e+00 - rotation_loss: 146.1686 - classification_accuracy: 0.1000 - rotation_accuracy: 0.2497 - val_loss: 2306.3369 - val_classification_loss: 0.4212 - val_rotation_loss: 11.5296 - val_classification_accuracy: 0.0022 - val_rotation_accuracy: 0.2502\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 329s 263ms/step - loss: 35910.1875 - classification_loss: 0.0000e+00 - rotation_loss: 179.5511 - classification_accuracy: 0.0984 - rotation_accuracy: 0.2507 - val_loss: 26211.8418 - val_classification_loss: 4.8394 - val_rotation_loss: 131.0351 - val_classification_accuracy: 0.0019 - val_rotation_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 329s 263ms/step - loss: 38529.5859 - classification_loss: 0.0000e+00 - rotation_loss: 192.6479 - classification_accuracy: 0.0992 - rotation_accuracy: 0.2515 - val_loss: 31898.8105 - val_classification_loss: 5.8962 - val_rotation_loss: 159.4647 - val_classification_accuracy: 0.0020 - val_rotation_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 328s 263ms/step - loss: 45902.7344 - classification_loss: 0.0000e+00 - rotation_loss: 229.5135 - classification_accuracy: 0.0992 - rotation_accuracy: 0.2527 - val_loss: 48232.0000 - val_classification_loss: 10.9122 - val_rotation_loss: 241.1052 - val_classification_accuracy: 0.0021 - val_rotation_accuracy: 0.2526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34de14a828>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(1,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5814d06710fa1ab2eb306c97d24ec609388cf9dc442c28dc2a9b6d925a9517c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
